# src/unwrap_hard_wraps.py

import os
import re
from datetime import datetime
from utils.get_safe_path import get_safe_path
from utils.logger import Logger

# === å¯èª¿åƒæ•¸ï¼ˆå–®ä½ï¼šUTF-8 bytesï¼‰ ===
MIN_WRAP_LEN = 80    # è¦–ç‚ºã€Œå¾ˆé•·ä¸€è¡Œã€çš„é•·åº¦é–€æª»ï¼ˆå…¨è‹±æ–‡ç´„120å­—ï¼Œå…¨ä¸­æ–‡ç´„40å­—ï¼‰
TITLEISH_MAX = 64    # è¦–ç‚ºã€ŒçŸ­æ¨™é¡Œã€çš„é•·åº¦ä¸Šé™ï¼ˆå…¨è‹±æ–‡ç´„80å­—ï¼Œå…¨ä¸­æ–‡ç´„26å­—ï¼‰
SENTENCE_ENDERS = ("ã€‚", "ï¼", "ï¼Ÿ", ".", "!", "?")

# === åŸæœ¬çš„æ¨¡å¼åˆ¤æ–· ===
MD_TABLE_LINE = re.compile(r'^\s*\|')                  # è¡¨æ ¼
HR_LINE = re.compile(r'^\s*(-{3,}|\*{3,}|_{3,})\s*$')  # --- *** ___
ATX_HEADING = re.compile(r'^\s{0,3}#{1,6}\s')          # #, ##, ...
LIST_BULLET = re.compile(r'^\s{0,}[*\-+]\s+')
LIST_ORDERED = re.compile(r'^\s{0,}\d{1,3}[.)]\s+')
BLOCKQUOTE = re.compile(r'^\s{0,3}>\s?')
CODE_FENCE = re.compile(r'^\s{0,3}```')

HARD_BREAK = re.compile(r'(  |\s\\)$')                 # å…©ç©ºç™½æˆ–åæ–œç·šçµå°¾çš„å¼·åˆ¶æ›è¡Œ
BQ_PREFIX = re.compile(r'^(\s{0,3}>\s?)')              # æŠ“ blockquote å‰ç¶´ï¼ˆæ”¯æ´æœ€å¤š3ç©ºç™½ï¼‰

def split_bq_prefix(line: str):
    """å›å‚³ (prefix, payload)ã€‚è‹¥é blockquote å‰‡ prefix=""ã€payload=line"""
    m = BQ_PREFIX.match(line)
    if not m:
        return "", line
    return m.group(0), line[m.end():]

def find_yaml_block(lines):
    """å›å‚³ (start, end) æˆ– (None, None)"""
    boundaries = [i for i, l in enumerate(lines[:20]) if l.strip() == "---"]
    if len(boundaries) >= 2 and boundaries[0] == 0:
        return boundaries[0], boundaries[1]
    return None, None

# === å·¥å…·å‡½å¼ ===
def is_header_line(s: str) -> bool:
    return ATX_HEADING.match(s.lstrip()) is not None

def block_start_reason(s: str) -> str | None:
    t = s.lstrip()
    if t == "":
        return "blank"
    if LIST_BULLET.match(t):
        return "list_bullet"
    if LIST_ORDERED.match(t):
        return "list_ordered"
    if BLOCKQUOTE.match(t):
        return "blockquote"
    if CODE_FENCE.match(t):
        return "fence"
    if MD_TABLE_LINE.match(t):
        return "table"
    if HR_LINE.match(t):
        return "hr"
    if t.startswith("<"):
        return "html"
    if ATX_HEADING.match(t):
        return "heading"
    return None

def is_block_starter(s: str) -> bool:
    return block_start_reason(s) is not None

def looks_titleish(s: str) -> bool:
    """çŸ­ã€åƒæ¨™é¡Œ/åè©/é€£çµçš„è¡Œï¼šä¸ç•¶ä½œçºŒè¡Œä¾†æº"""
    txt = s.strip()
    if len(txt.encode("utf-8")) <= TITLEISH_MAX:
        if txt.endswith(("]]", ")")):
            return True
        if (txt.startswith("**") and txt.endswith("**")) or (txt.startswith("[[") and txt.endswith("]]")):
            return True
        # æ²’æœ‰å†’è™Ÿã€å–®å­—éƒ½ä¸å¤ªé•· â†’ é¡æ¨™é¡Œ/åè©ç‰‡æ®µ
        if ":" not in txt and all(len(w) <= 20 for w in txt.replace("**", "").split()):
            return True
    return False

def ends_with_forced_break(prev_raw: str) -> bool:
    return HARD_BREAK.search(prev_raw.rstrip("\n")) is not None

def get_leading_indent(line: str, tab_size=4) -> int:
    n = 0
    for ch in line:
        if ch == " ":
            n += 1
        elif ch == "\t":
            n += tab_size
        else:
            break
    return n

# === åˆä½µåˆ¤æ–·ï¼ˆä¿å®ˆï¼Œä¸¦è¼¸å‡ºç†ç”±ï¼‰ ===
def should_unwrap(prev_line: str, curr_line: str, log, rel, i,
                  prev_is_list: bool, next_indented_text: bool, same_bq_level: bool) -> bool:
    ps_raw = prev_line.rstrip("\n")
    cs_raw = curr_line.rstrip("\n")
    ps = ps_raw.strip()
    cs = cs_raw.strip()

    prev_indent = get_leading_indent(prev_line)
    curr_indent = get_leading_indent(curr_line)
    prev_len_bytes = len(ps.encode("utf-8"))

    # å…ˆåˆ¤æ–·ã€Œä¸‹ä¸€è¡Œæ˜¯å¦ç‚ºå€å¡Šèµ·é»ã€ï¼ˆé™¤éåŒå±¤ blockquoteï¼‰
    nxt_reason = block_start_reason(curr_line)
    if nxt_reason and not same_bq_level:
        log(f"â›” [{rel}] L{i}->{i+1} stop: nxt is block starter ({nxt_reason})")
        return False

    # è©³ç´°æ±ºç­– logï¼ˆåŒä¸€è¡Œå…ˆä¸æ›è¡Œï¼‰
    log(f"ğŸ” [{rel}] L{i}->{i+1}: prev_bytes={prev_len_bytes}, prev_indent={prev_indent}, curr_indent={curr_indent}, same_bq={same_bq_level} | ", end="")

    # --- ğŸ”§ é—œéµï¼šæ¸…å–®çºŒè¡Œçš„ç‰¹ä¾‹è¦ã€Œå…ˆåˆ¤æ–·ã€ ---
    # åªè¦ä¸Šä¸€è¡Œæ˜¯æ¸…å–®é …ï¼Œä¸”ä¸‹ä¸€è¡Œæ˜¯ç¸®æ’çš„ç´”æ–‡å­—ï¼ˆä¸æ˜¯æ–°çš„æ¸…å–®/ç·¨è™Ÿ/blockquote/åœæ¬„ï¼‰ï¼Œå°±åˆä½µ
    if prev_is_list and next_indented_text:
        log("âœ… MERGE â€” LIST-CONT: prev_is_list & next_indented_text")
        return True

    # ä¸€èˆ¬æ—©é€€æ¢ä»¶
    if not cs:
        log("ğŸš« SKIP â€” next is empty")
        return False
    if is_header_line(ps):
        log("ğŸš« SKIP â€” prev is heading")
        return False
    if is_block_starter(ps):
        log("ğŸš« SKIP â€” prev is block starter")
        return False
    if looks_titleish(ps) and prev_len_bytes < MIN_WRAP_LEN:
        log("ğŸš« SKIP â€” prev looks titleish/short")
        return False
    if ps.endswith(SENTENCE_ENDERS):
        log("ğŸš« SKIP â€” prev ends with sentence ender")
        return False
    if ends_with_forced_break(prev_line):
        log("ğŸš« SKIP â€” prev has HARD_BREAK")
        return False

    # åŒå±¤é•·è¡Œ â†’ åˆä½µ
    if curr_indent == prev_indent and prev_len_bytes >= MIN_WRAP_LEN:
        log(f"âœ… MERGE â€” same indent & long prev ({prev_len_bytes} >= {MIN_WRAP_LEN})")
        return True

    # æ¬¡å±¤æ›´æ·±ä¸”é•·è¡Œ â†’ åˆä½µï¼ˆå¸¸è¦‹æ®µè½çºŒè¡Œï¼‰
    if curr_indent > prev_indent and prev_len_bytes >= MIN_WRAP_LEN:
        log(f"âœ… MERGE â€” next deeper indent & long prev ({prev_len_bytes} >= {MIN_WRAP_LEN})")
        return True

    log("ğŸš« SKIP â€” default (did not meet merge conditions)")
    return False

# === ä¸»æµç¨‹ ===
def unwrap_hard_wraps(vault_path, log_path=None, verbose=False):
    changed_files = 0
    changed_lines_total = 0

    logger = Logger(log_path=log_path, verbose=verbose, title="Unwrap Hard Wraps Log")
    log = logger.log
    log(f"ğŸ§µ Unwrap Hard Wraps Log â€” {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\n")
    log(f"Params: MIN_WRAP_LEN={MIN_WRAP_LEN} bytes, TITLEISH_MAX={TITLEISH_MAX} bytes\n")

    for root, _, files in os.walk(vault_path):
        for file in files:
            if not file.endswith(".md"):
                continue

            fp = os.path.join(root, file)
            sfp = get_safe_path(fp)
            rel = os.path.relpath(fp, vault_path)

            with open(sfp, "r", encoding="utf-8") as f:
                lines = f.readlines()

            yaml_start, yaml_end = find_yaml_block(lines)
            in_fence = False
            out = []
            i = 0
            merged_count = 0

            def in_yaml(idx):
                return yaml_start is not None and yaml_start <= idx <= yaml_end

            while i < len(lines):
                line = lines[i]

                # YAML å€å¡Šä¿ç•™
                if in_yaml(i):
                    out.append(line)
                    i += 1
                    continue

                # fenced code åˆ‡æ›
                if CODE_FENCE.match(line):
                    in_fence = not in_fence
                    out.append(line)
                    i += 1
                    continue

                # ä»£ç¢¼æˆ–è¡¨æ ¼ä¿ç•™
                if in_fence or MD_TABLE_LINE.match(line):
                    out.append(line)
                    i += 1
                    continue

                # ä»¥ curr ç‚ºåŸºåº•ä¸€è·¯å˜—è©¦åƒå¾Œé¢èƒ½åˆçš„è¡Œï¼ˆé€£é–åˆä½µï¼‰
                curr = line
                j = i + 1

                while j < len(lines):
                    nxt = lines[j]

                    # ä¸‹ä¸€è¡Œè‹¥åœ¨ YAML / fence / è¡¨æ ¼ / ç¸®æ’ codeï¼Œç›´æ¥åœ
                    if in_yaml(j) or in_fence or MD_TABLE_LINE.match(nxt):
                        log(f"â›” [{rel}] L{i}->{j} stop: yaml/fence/table/indented-code boundary")
                        break

                    # blockquote å…§å…è¨±åˆä½µï¼šprev/nxt éƒ½æ˜¯ blockquote ä¸”å‰ç¶´ä¸€è‡´æ‰ç®—ã€ŒåŒä¸€å±¤ã€
                    curr_bq, curr_body = split_bq_prefix(curr)
                    nxt_bq, nxt_body = split_bq_prefix(nxt)
                    same_bq_level = (curr_bq != "" and curr_bq == nxt_bq)

                    # åµæ¸¬ã€Œä¸Šä¸€è¡Œæ˜¯æ¸…å–®ã€ã€Œä¸‹ä¸€è¡Œåªæ˜¯åŒé …ç›®çš„ç¸®æ’çºŒè¡Œã€
                    prev_is_list = bool(LIST_BULLET.match(curr) or LIST_ORDERED.match(curr))
                    next_indented_text = bool(
                        (nxt.startswith("  ") or nxt.startswith("\t")) and
                        not (LIST_BULLET.match(nxt) or LIST_ORDERED.match(nxt) or BLOCKQUOTE.match(nxt) or CODE_FENCE.match(nxt))
                    )


                    # åˆ¤æ–·æ˜¯å¦åˆä½µï¼ˆå«è©³ç´°ç†ç”±è¼¸å‡ºï¼‰
                    if should_unwrap(
                        curr,
                        nxt,
                        log,
                        rel,
                        j,  # ç”¨ç•¶å‰é…å°çš„è¡Œè™Ÿåšé¡¯ç¤ºï¼ˆprev=j-1, next=jï¼‰
                        prev_is_list,
                        next_indented_text,
                        same_bq_level
                    ):
                        # çœŸçš„åˆä½µï¼šè™•ç† blockquote åŠç©ºç™½
                        if same_bq_level:
                            merged = curr_bq + curr_body.rstrip("\n").rstrip() + " " + nxt_body.lstrip()
                        else:
                            merged = curr.rstrip("\n").rstrip() + " " + nxt.lstrip()
                        curr = merged
                        j += 1
                        merged_count += 1
                        continue
                    else:
                        break

                out.append(curr)
                i = j

            if out != lines:
                with open(sfp, "w", encoding="utf-8") as f:
                    f.writelines(out)
                changed_files += 1
                changed_lines_total += merged_count
                log(f"âœ… {rel}ï¼šåˆä½µ {merged_count} è™•ç¡¬æ–·è¡Œ")
            else:
                log(f"â˜‘ï¸ {rel}ï¼šç„¡éœ€è®Šæ›´")

    log(f"\nğŸ“Š çµ±è¨ˆï¼šä¿®æ­£ {changed_files} ä»½æª”æ¡ˆï¼Œå…±åˆä½µ {changed_lines_total} è™•ç¡¬æ–·è¡Œ")
    logger.save()
    return changed_files, changed_lines_total


if __name__ == "__main__":
    BASE_DIR = os.path.abspath(os.path.join(os.path.dirname(__file__), ".."))
    VAULT = os.path.join(BASE_DIR, "TestData")
    LOG = os.path.join(BASE_DIR, "log", "unwrap_hard_wraps.log")
    unwrap_hard_wraps(VAULT, log_path=LOG, verbose=True)
