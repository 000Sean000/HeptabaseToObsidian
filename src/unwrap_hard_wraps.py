# src/unwrap_hard_wraps.py

import os
import re
from datetime import datetime
from utils.get_safe_path import get_safe_path
from utils.logger import Logger

# === å¯èª¿åƒæ•¸ï¼ˆå–®ä½ï¼šUTF-8 bytesï¼‰ ===
MIN_WRAP_LEN = 80     # è¦–ç‚ºã€Œå¾ˆé•·ä¸€è¡Œã€çš„é•·åº¦é–€æª»ï¼ˆå…¨è‹±æ–‡ç´„120å­—ï¼Œå…¨ä¸­æ–‡ç´„40å­—ï¼‰
TITLEISH_MAX = 64     # è¦–ç‚ºã€ŒçŸ­æ¨™é¡Œã€çš„é•·åº¦ä¸Šé™ï¼ˆå…¨è‹±æ–‡ç´„80å­—ï¼Œå…¨ä¸­æ–‡ç´„26å­—ï¼‰
SENTENCE_ENDERS = ("ã€‚", "ï¼", "ï¼Ÿ", ".", "!", "?")

# === Markdown æ¨¡å¼ ===
MD_TABLE_LINE = re.compile(r'^\s*\|')   # è¡¨æ ¼
HR_LINE = re.compile(r'^\s*(-{3,}|\*{3,}|_{3,})\s*$')
ATX_HEADING = re.compile(r'^\s{0,3}#{1,6}\s')
LIST_BULLET = re.compile(r'^\s{0,}[*\-+]\s+')
LIST_ORDERED = re.compile(r'^\s{0,}\d{1,3}[.)]\s+')
BLOCKQUOTE = re.compile(r'^\s{0,3}>\s?')
CODE_FENCE = re.compile(r'^\s{0,3}```')
HARD_BREAK = re.compile(r'(  |\s\\)$')  # å…©ç©ºç™½æˆ–åæ–œç·šçµå°¾çš„å¼·åˆ¶æ›è¡Œ
BQ_PREFIX = re.compile(r'^(\s{0,3}>\s?)')  # æŠ“ blockquote å‰ç¶´ï¼ˆæ”¯æ´æœ€å¤š3ç©ºç™½ï¼‰

# å–å¾—ä¸‹ä¸€è¡Œç¬¬ä¸€å€‹ tokenï¼ˆæ•´å€‹ [[Wikilink]] æˆ–è‹±æ•¸è©ï¼‰
NEXT_TOKEN_RE = re.compile(r'^\s*(\[\[[^\]]+\]\]|[A-Za-z0-9][A-Za-z0-9_\-]*)')

# å–®è¡Œç´” wikilinkï¼ˆå¯å¸¶ aliasï¼‰
_PURE_WIKILINK = re.compile(r'^\s*\[\[[^|\]]+(?:\|[^\]]+)?\]\]\s*$')

def is_pure_wikilink(s: str) -> bool:
    return bool(_PURE_WIKILINK.match(s.strip()))

def split_bq_prefix(line: str):
    """å›å‚³ (prefix, payload)ã€‚è‹¥é blockquote å‰‡ prefix=""ã€payload=line"""
    m = BQ_PREFIX.match(line)
    if not m:
        return "", line
    return m.group(0), line[m.end():]

def find_yaml_block(lines):
    """å›å‚³ (start, end) æˆ– (None, None)"""
    boundaries = [i for i, l in enumerate(lines[:20]) if l.strip() == "---"]
    if len(boundaries) >= 2 and boundaries[0] == 0:
        return boundaries[0], boundaries[1]
    return None, None

# === å·¥å…·å‡½å¼ ===
def is_header_line(s: str) -> bool:
    return ATX_HEADING.match(s.lstrip()) is not None

def block_start_reason(s: str) -> str:
    t = s.lstrip()
    if t == "":
        return "blank"
    if ATX_HEADING.match(t):
        return "heading"
    if LIST_BULLET.match(t):
        return "list_bullet"
    if LIST_ORDERED.match(t):
        return "list_ordered"
    if BLOCKQUOTE.match(t):
        return "blockquote"
    if CODE_FENCE.match(t):
        return "code_fence"
    if MD_TABLE_LINE.match(t):
        return "table"
    if HR_LINE.match(t):
        return "hr"
    if t.startswith("<"):
        return "html"
    return ""

def is_block_starter(s: str) -> bool:
    return block_start_reason(s) != ""

def looks_titleish(s: str) -> bool:
    """çŸ­ã€åƒæ¨™é¡Œ/åè©/é€£çµçš„è¡Œï¼šä¸ç•¶ä½œçºŒè¡Œä¾†æº"""
    txt = s.strip()
    if len(txt.encode("utf-8")) <= TITLEISH_MAX:
        # ç´”é€£çµ/ç²—é«”/åè©å‚¾å‘
        if txt.endswith(("]]", ")")):
            return True
        if (txt.startswith("**") and txt.endswith("**")) or (txt.startswith("[[") and txt.endswith("]]")):
            return True
        # åªæœ‰ä¸€å…©å€‹è©çš„æ¨™é¡Œæ„Ÿ
        if ":" not in txt and all(len(w) <= 20 for w in txt.replace("**", "").split()):
            return True
    return False

def ends_with_forced_break(prev_raw: str) -> bool:
    return HARD_BREAK.search(prev_raw.rstrip("\n")) is not None

def get_leading_indent(line: str, tab_size=4) -> int:
    n = 0
    for ch in line:
        if ch == " ":
            n += 1
        elif ch == "\t":
            n += tab_size
        else:
            break
    return n

def first_token_bytes(s: str) -> int:
    """
    å–å¾—ä¸‹ä¸€è¡Œé–‹é ­ç¬¬ä¸€å€‹ã€Œè©ã€çš„ UTF-8 byte é•·åº¦ï¼š
    - [[...]] è¦–ç‚ºä¸€å€‹è©
    - å¦å‰‡å–ç¬¬ä¸€å€‹è‹±æ•¸è©ï¼ˆå…è¨± -/_ï¼‰
    å–ä¸åˆ°å‰‡å› 0
    """
    m = NEXT_TOKEN_RE.match(s)
    if not m:
        return 0
    return len(m.group(1).encode("utf-8"))

# === è¶…ä¿å®ˆçš„åˆä½µåˆ¤æ–· ===
def should_unwrap(
    prev_line: str,
    curr_line: str,
    *,
    prev_is_list: bool,
    next_indented_text: bool,
    same_bq_level: bool,
    log,
    rel: str,
    i: int
) -> bool:
    ps_raw = prev_line.rstrip("\n")
    cs_raw = curr_line.rstrip("\n")
    ps = ps_raw.strip()
    cs = cs_raw.strip()

    prev_indent = get_leading_indent(prev_line)
    curr_indent = get_leading_indent(curr_line)

    # å…ˆçœ‹ã€Œä¸‹ä¸€è¡Œã€æ˜¯å¦ç‚ºå€å¡Šèµ·é»ï¼ˆåŒå±¤ blockquote ä¾‹å¤–ï¼‰
    nxt_r = block_start_reason(curr_line)
    if nxt_r and not same_bq_level:
        log(f"â›” [{rel}] L{i}->{i+1} stop: nxt is block starter ({nxt_r})")
        return False

    prev_len_bytes = len(ps.encode("utf-8"))

    # è©³ç´°æ±ºç­– baseline
    base = f"ğŸ” [{rel}] L{i}->{i+1}: prev_bytes={prev_len_bytes}, prev_indent={prev_indent}, curr_indent={curr_indent}, same_bq={same_bq_level}"

    # ç©ºè¡Œä¸åˆä½µ
    if not cs:
        log(f"{base} | ğŸš« SKIP â€” next is empty")
        return False

    # --- æ¸…å–®çºŒè¡Œçš„ç‰¹ä¾‹ï¼ˆè¦æ”¾æ—©ï¼‰ ---
    # ä½†è‹¥ã€Œä¸Šä¸€è¡ŒåƒçŸ­æ¨™é¡Œ/å–®ä¸€ wikilinkã€æˆ–ã€Œä¸‹ä¸€è¡Œæ˜¯ç´” wikilink æ•´è¡Œã€ï¼Œå‰‡ä¸è¦åˆä½µ
    if prev_is_list and next_indented_text and not looks_titleish(ps) and not is_pure_wikilink(cs):
        log(f"{base} | âœ… MERGE â€” LIST-CONT: prev_is_list & next_indented_text")
        return True

    # ä¸€èˆ¬æ—©é€€æ¢ä»¶
    if is_header_line(ps):
        log(f"{base} | ğŸš« SKIP â€” prev is heading")
        return False
    if is_block_starter(ps):
        log(f"{base} | ğŸš« SKIP â€” prev is block starter")
        return False
    if looks_titleish(ps) and prev_len_bytes < MIN_WRAP_LEN:
        log(f"{base} | ğŸš« SKIP â€” prev looks titleish/short")
        return False
    if ps.endswith(SENTENCE_ENDERS):
        log(f"{base} | ğŸš« SKIP â€” prev ends with sentence ender")
        return False
    if ends_with_forced_break(prev_line):
        log(f"{base} | ğŸš« SKIP â€” prev has HARD_BREAK")
        return False

    # â€”â€” æœ‰æ•ˆé•·åº¦ï¼šæ¨¡æ“¬è‡ªå‹• word-wrapï¼ˆæŠŠä¸‹ä¸€è¡Œç¬¬ä¸€å€‹ token ä¹Ÿç®—é€²é–€æª»ï¼‰â€”â€”
    eff_prev_len = prev_len_bytes
    if curr_indent >= prev_indent:  # åƒ…åŒå±¤æˆ–æ›´æ·±ç¸®æ’æ‰å¯èƒ½æ˜¯çºŒå¥
        add = first_token_bytes(cs)
        if add > 0:
            eff_prev_len += add + 1  # +1 æ¨¡æ“¬ join æ™‚æœƒåŠ ä¸Šçš„ç©ºç™½

    # åˆä½µæ¢ä»¶
    if curr_indent == prev_indent and eff_prev_len >= MIN_WRAP_LEN:
        log(f"{base} | âœ… MERGE â€” same indent & effective prev len ({eff_prev_len} >= {MIN_WRAP_LEN})")
        return True

    if curr_indent > prev_indent and eff_prev_len >= MIN_WRAP_LEN:
        log(f"{base} | âœ… MERGE â€” next deeper indent & effective prev len ({eff_prev_len} >= {MIN_WRAP_LEN})")
        return True

    log(f"{base} | ğŸš« SKIP â€” default (did not meet merge conditions)")
    return False

# === ä¸»æµç¨‹ ===
def unwrap_hard_wraps(vault_path, log_path=None, verbose=False):
    changed_files = 0
    changed_lines_total = 0

    logger = Logger(log_path=log_path, verbose=verbose, title="Unwrap Hard Wraps Log")
    log = logger.log
    log(f"ğŸ§µ Unwrap Hard Wraps Log â€” {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\n")
    log(f"Params: MIN_WRAP_LEN={MIN_WRAP_LEN} bytes, TITLEISH_MAX={TITLEISH_MAX} bytes\n")

    for root, _, files in os.walk(vault_path):
        for file in files:
            if not file.endswith(".md"):
                continue

            fp = os.path.join(root, file)
            sfp = get_safe_path(fp)
            rel = os.path.relpath(fp, vault_path)

            try:
                with open(sfp, "r", encoding="utf-8") as f:
                    lines = f.readlines()
            except Exception as e:
                log(f"âš ï¸  ç„¡æ³•è®€å– {rel}: {e}")
                continue

            yaml_start, yaml_end = find_yaml_block(lines)
            in_fence = False
            out = []
            i = 0
            merged_count = 0

            def in_yaml(idx):
                return yaml_start is not None and yaml_start <= idx <= yaml_end

            while i < len(lines):
                line = lines[i]

                # YAML å€å¡Šä¿ç•™
                if in_yaml(i):
                    out.append(line)
                    i += 1
                    continue

                # fenced code åˆ‡æ›
                if CODE_FENCE.match(line):
                    in_fence = not in_fence
                    out.append(line)
                    i += 1
                    continue

                # è¡¨æ ¼è¡Œä¿ç•™ï¼ˆä¸è·¨è¡Œåˆä½µï¼‰
                if in_fence or MD_TABLE_LINE.match(line):
                    out.append(line)
                    i += 1
                    continue

                # å˜—è©¦ã€Œé€£é–åˆä½µã€ï¼šä»¥ curr ç‚ºåŸºåº•ä¸€è·¯åƒèƒ½ä½µçš„ä¸‹ä¸€è¡Œ
                curr = line
                j = i + 1

                while j < len(lines):
                    nxt = lines[j]

                    # ä¸‹ä¸€è¡Œè‹¥æ˜¯ YAML/fence/è¡¨æ ¼ï¼Œæˆ–æˆ‘å€‘ç›®å‰åœ¨ fence ä¸­ï¼Œå°±åœ
                    if in_yaml(j) or in_fence or MD_TABLE_LINE.match(nxt):
                        reason = "yaml/fence/table boundary"
                        log(f"â›” [{rel}] L{i}->{j} stop: {reason}")
                        break

                    # å…è¨±åœ¨åŒå±¤ blockquote å…§åˆä½µï¼šåªè¦ prev/nxt éƒ½æ˜¯ blockquote ä¸”å‰ç¶´ä¸€è‡´
                    curr_bq, curr_body = split_bq_prefix(curr)
                    nxt_bq, nxt_body = split_bq_prefix(nxt)
                    same_bq_level = (curr_bq != "" and curr_bq == nxt_bq)

                    # è¨ˆç®—æ¸…å–®çºŒè¡Œæ——æ¨™
                    prev_is_list = bool(LIST_BULLET.match(curr.lstrip()) or LIST_ORDERED.match(curr.lstrip()))
                    next_indented_text = bool(
                        (nxt.startswith("  ") or nxt.startswith("\t")) and
                        not (LIST_BULLET.match(nxt) or LIST_ORDERED.match(nxt) or BLOCKQUOTE.match(nxt) or CODE_FENCE.match(nxt) or ATX_HEADING.match(nxt))
                    )

                    # åˆ¤æ–·æ˜¯å¦åˆä½µ
                    if should_unwrap(
                        curr, nxt,
                        prev_is_list=prev_is_list,
                        next_indented_text=next_indented_text,
                        same_bq_level=same_bq_level,
                        log=log, rel=rel, i=j-1
                    ):
                        if same_bq_level:
                            # blockquote å…§éƒ¨åˆä½µï¼šä¿ç•™ä¸€å€‹å‰ç¶´ï¼ŒæŠŠå…§å®¹æ¥èµ·ä¾†
                            merged = curr_bq + curr_body.rstrip("\n").rstrip() + " " + nxt_body.lstrip()
                        else:
                            merged = curr.rstrip("\n").rstrip() + " " + nxt.lstrip()
                        curr = merged
                        j += 1
                        merged_count += 1
                        continue
                    else:
                        break

                # å¯«å‡ºæœ¬æ®µï¼ˆå¯èƒ½å·²åˆä½µå¤šè¡Œï¼‰
                out.append(curr)
                i = j

            if out != lines:
                try:
                    with open(sfp, "w", encoding="utf-8") as f:
                        f.writelines(out)
                    changed_files += 1
                    changed_lines_total += merged_count
                    log(f"âœ… {rel}ï¼šåˆä½µ {merged_count} è™•ç¡¬æ–·è¡Œ")
                except Exception as e:
                    log(f"âš ï¸  ç„¡æ³•å¯«å…¥ {rel}: {e}")
            else:
                log(f"â˜‘ï¸ {rel}ï¼šç„¡éœ€è®Šæ›´")

    log(f"\nğŸ“Š çµ±è¨ˆï¼šä¿®æ­£ {changed_files} ä»½æª”æ¡ˆï¼Œå…±åˆä½µ {changed_lines_total} è™•ç¡¬æ–·è¡Œ")
    logger.save()
    return changed_files, changed_lines_total


if __name__ == "__main__":
    BASE_DIR = os.path.abspath(os.path.join(os.path.dirname(__file__), ".."))
    VAULT = os.path.join(BASE_DIR, "TestData")
    LOG = os.path.join(BASE_DIR, "log", "unwrap_hard_wraps.log")
    unwrap_hard_wraps(VAULT, log_path=LOG, verbose=True)
